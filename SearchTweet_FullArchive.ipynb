{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SearchTweet_FullArchive.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7mQPsHJBohkn8Y5RjYS/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theclassofai/TweetSearch_FullArchive/blob/main/SearchTweet_FullArchive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Tweets \n",
        "\n",
        "This document shows how to use Tweepy to conduct a full archive search using v2 of the Twitter API.\n",
        "\n",
        "## Prep work\n",
        "In order to use this code, you will need to have a developer account on Twitter, with access to the Academic Research product track. Information about who is eligible and how to apply is here.\n",
        "\n",
        "Once you have an account, you will need to create a new app at https://developer.twitter.com/en/portal/dashboard and generate a \"bearer token\" from the app. Copy the bearer token to your clipboard and paste it into a new file in the same directory as this file, called twitter_authentication.py. The entire contents of the file should look like this:\n",
        "\n",
        "`bearer_token = \"YOUR BEARER TOKEN HERE\"`\n",
        "Note that you should never share this token with anyone else. If, for example, you are saving your work in a Git repository, make sure that you add the twitter_authentication.py file to your .gitignore.\n",
        "\n",
        "If anyone gets this token, they will have access to your Twitter account and you will need to revoke the token (from the same interface where you created it)."
      ],
      "metadata": {
        "id": "DeOAfazTA0vN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXquFNtYg9Im",
        "outputId": "cca0d678-5f97-402f-9021-fe45be4d37a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tweepy==4.4.0\n",
            "  Downloading tweepy-4.4.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 65 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib<2,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tweepy==4.4.0) (1.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy==4.4.0) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.11.1->tweepy==4.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.11.1->tweepy==4.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.11.1->tweepy==4.4.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.11.1->tweepy==4.4.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib<2,>=1.0.0->tweepy==4.4.0) (3.1.1)\n",
            "Installing collected packages: tweepy\n",
            "  Attempting uninstall: tweepy\n",
            "    Found existing installation: tweepy 3.10.0\n",
            "    Uninstalling tweepy-3.10.0:\n",
            "      Successfully uninstalled tweepy-3.10.0\n",
            "Successfully installed tweepy-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy==4.4.0\n",
        "import tweepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "from twitter_authentication import bearer_token\n",
        "import time\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4h9tZCpZhZlQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n"
      ],
      "metadata": {
        "id": "OCjaaKdLh-mb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hoax_tweets = []\n",
        "for response in tweepy.Paginator(client.search_all_tweets, \n",
        "                                 query = 'ممشى الالوان جدة',\n",
        "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
        "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
        "                                 expansions = 'author_id',\n",
        "                                 start_time = '2021-01-20T00:00:00Z',\n",
        "                                 end_time = '2021-10-21T00:00:00Z',\n",
        "                              max_results=500):\n",
        "    time.sleep(1)\n",
        "    hoax_tweets.append(response)"
      ],
      "metadata": {
        "id": "jwhlHPdxiFDg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hoax_tweets[0].data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl01f2Bz5XBZ",
        "outputId": "b47fafd2-bd3f-4531-fc11-4afbcedc81f4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Tweet id=1446476856962736132 text=RT @MBR012: @med_projects اتوقع بيكون مثل ممشى الألوان في جدة https://t.co/4JtWubOapH>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "user_dict = {}\n",
        "# Loop through each response object\n",
        "for response in hoax_tweets:\n",
        "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
        "    for user in response.includes['users']:\n",
        "        user_dict[user.id] = {'username': user.username, \n",
        "                              'followers': user.public_metrics['followers_count'],\n",
        "                              'tweets': user.public_metrics['tweet_count'],\n",
        "                              'description': user.description,\n",
        "                              'location': user.location\n",
        "                             }\n",
        "    for tweet in response.data:\n",
        "        # For each tweet, find the author's information\n",
        "        author_info = user_dict[tweet.author_id]\n",
        "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
        "        result.append({'author_id': tweet.author_id, \n",
        "                       'username': author_info['username'],\n",
        "                       'author_followers': author_info['followers'],\n",
        "                       'author_tweets': author_info['tweets'],\n",
        "                       'author_description': author_info['description'],\n",
        "                       'author_location': author_info['location'],\n",
        "                       'text': tweet.text,\n",
        "                       'created_at': tweet.created_at,\n",
        "                       'retweets': tweet.public_metrics['retweet_count'],\n",
        "                       'replies': tweet.public_metrics['reply_count'],\n",
        "                       'likes': tweet.public_metrics['like_count'],\n",
        "                       'quote_count': tweet.public_metrics['quote_count']\n",
        "                      })\n",
        "\n",
        "# Change this list of dictionaries into a dataframe\n",
        "df = pd.DataFrame(result)"
      ],
      "metadata": {
        "id": "r-yO2PGL5c1v"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('Arabic_Text2.csv', index=False)"
      ],
      "metadata": {
        "id": "HB8KKVa35e7k"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}